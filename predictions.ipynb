{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housingMedianAge  totalRooms  totalBedrooms  \\\n",
      "0    -122.23     37.88              41.0       880.0          129.0   \n",
      "1    -122.22     37.86              21.0      7099.0         1106.0   \n",
      "2    -122.24     37.85              52.0      1467.0          190.0   \n",
      "3    -122.25     37.85              52.0      1274.0          235.0   \n",
      "4    -122.25     37.85              52.0      1627.0          280.0   \n",
      "\n",
      "   population  households  medianIncome  rooms_per_household  \\\n",
      "0       322.0       126.0        8.3252             6.984127   \n",
      "1      2401.0      1138.0        8.3014             6.238137   \n",
      "2       496.0       177.0        7.2574             8.288136   \n",
      "3       558.0       219.0        5.6431             5.817352   \n",
      "4       565.0       259.0        3.8462             6.281853   \n",
      "\n",
      "   bedrooms_per_room  population_per_household  medianHouseValue  \n",
      "0           0.146591                  2.555556          452600.0  \n",
      "1           0.155797                  2.109842          358500.0  \n",
      "2           0.129516                  2.802260          352100.0  \n",
      "3           0.184458                  2.547945          341300.0  \n",
      "4           0.172096                  2.181467          342200.0  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"/home/nishanth/tensorflow/california_housing/cal_housing_edited.csv\")\n",
    "print data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalar = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(np.array(data), test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16512, 12) (4128, 12)\n"
     ]
    }
   ],
   "source": [
    "print train.shape, test.shape\n",
    "x_train, y_train ,x_test, y_test = train[:,:-1], train[:,-1], test[:,:-1], test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lreg = LinearRegression()\n",
    "X = scalar.fit_transform(x_train)\n",
    "Y = y_train\n",
    "lreg.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculating root mean square error of model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def error(model, X, Y):\n",
    "    predictions = model.predict(X)\n",
    "    mse = mean_squared_error(Y, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68311.8562967575\n"
     ]
    }
   ],
   "source": [
    "print error(lreg, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def cross_val(model):\n",
    "    scores = cross_val_score(model, X, Y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    return rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [65503.19601742 71822.27077741 67676.62308014 66640.50945839\n",
      " 69192.93621885 66072.79696621 65711.8862025  69367.83077433\n",
      " 73674.48726124 69735.41305941]\n",
      "mean: 68539.79498159068\n",
      "standard deviation: 2594.9543977641724\n"
     ]
    }
   ],
   "source": [
    "rmse_scores = cross_val(lreg)\n",
    "print \"scores:\",rmse_scores\n",
    "print \"mean:\",np.mean(rmse_scores)\n",
    "print \"standard deviation:\",np.std(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "random_forest = RandomForestRegressor()\n",
    "random_forest.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22911.982666883323\n"
     ]
    }
   ],
   "source": [
    "print error(random_forest, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [52112.8878655  56358.42643414 52829.32203417 54870.28910783\n",
      " 55899.90323214 50894.44619137 52328.52601934 55386.14143807\n",
      " 53780.13478363 54604.25147596]\n",
      "mean: 53906.432858214204\n",
      "standard deviation: 1718.9089576757333\n"
     ]
    }
   ],
   "source": [
    "rmse_scores = cross_val(random_forest)\n",
    "print \"scores:\",rmse_scores\n",
    "print \"mean:\",np.mean(rmse_scores)\n",
    "print \"standard deviation:\",np.std(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random forest regressor worked better, lets do some hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]}, {'n_estimators': [3, 10], 'max_features': [2, 3, 4], 'bootstrap': [False]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "              {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}]\n",
    "\n",
    "reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(reg, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features=4, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=30, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print \"Best model:\",grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66926.33555438208, {'max_features': 2, 'n_estimators': 3})\n",
      "(56471.889376170795, {'max_features': 2, 'n_estimators': 10})\n",
      "(54133.45021531602, {'max_features': 2, 'n_estimators': 30})\n",
      "(61463.344792676166, {'max_features': 4, 'n_estimators': 3})\n",
      "(53620.01882275809, {'max_features': 4, 'n_estimators': 10})\n",
      "(51344.271366321365, {'max_features': 4, 'n_estimators': 30})\n",
      "(59506.280797152205, {'max_features': 6, 'n_estimators': 3})\n",
      "(53560.469160220055, {'max_features': 6, 'n_estimators': 10})\n",
      "(51509.80254841379, {'max_features': 6, 'n_estimators': 30})\n",
      "(60708.60886528652, {'max_features': 8, 'n_estimators': 3})\n",
      "(54017.6598259094, {'max_features': 8, 'n_estimators': 10})\n",
      "(52107.34862496689, {'max_features': 8, 'n_estimators': 30})\n",
      "(64059.44264475985, {'max_features': 2, 'n_estimators': 3, 'bootstrap': False})\n",
      "(55719.98784049514, {'max_features': 2, 'n_estimators': 10, 'bootstrap': False})\n",
      "(61012.03789792791, {'max_features': 3, 'n_estimators': 3, 'bootstrap': False})\n",
      "(53161.105067472556, {'max_features': 3, 'n_estimators': 10, 'bootstrap': False})\n",
      "(61086.15904679877, {'max_features': 4, 'n_estimators': 3, 'bootstrap': False})\n",
      "(52287.19446083154, {'max_features': 4, 'n_estimators': 10, 'bootstrap': False})\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is  (51127.42695126984, {'max_features': 4, 'n_estimators': 30})\n"
     ]
    }
   ],
   "source": [
    "print \"Best model is \",\"(51127.42695126984, {'max_features': 4, 'n_estimators': 30})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3531039582784274, 'medianIncome'),\n",
       " (0.14050440443019557, 'bedrooms_per_room'),\n",
       " (0.12772935950491887, 'population_per_household'),\n",
       " (0.09688044581680254, 'latitude'),\n",
       " (0.09397803422836293, 'longitude'),\n",
       " (0.05909052808819658, 'rooms_per_household'),\n",
       " (0.05268969496246531, 'housingMedianAge'),\n",
       " (0.019891067062357288, 'population'),\n",
       " (0.019034202702069826, 'totalBedrooms'),\n",
       " (0.01884097868338186, 'totalRooms'),\n",
       " (0.01825732624282189, 'households')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feature importance\n",
    "names = data.columns.values\n",
    "sorted(zip(feature_importances, names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set mse before grid search: 82288.43423379771\n",
      "Test set mse after grid search: 72080.28547273835\n"
     ]
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "X_test = scalar.fit_transform(x_test)\n",
    "print \"Test set mse before grid search:\",error(random_forest, X_test, y_test)\n",
    "print \"Test set mse after grid search:\", error(final_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
